{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vertebral_bone_ grade_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"G0K52coUTI6d","colab_type":"text"},"source":["**取得google drive認證**"]},{"cell_type":"code","metadata":{"id":"SbqY0C98yM0k","colab_type":"code","outputId":"3d21e358-8a82-4d61-dd0b-770378f21607","executionInfo":{"status":"ok","timestamp":1578582686900,"user_tz":-480,"elapsed":17912,"user":{"displayName":"林映辰林映辰","photoUrl":"","userId":"18165578179636605442"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g6F81fG_TK5k","colab_type":"text"},"source":["**設定path(本目錄的絕對路徑)**"]},{"cell_type":"markdown","metadata":{"id":"zsBbok6qTMz1","colab_type":"text"},"source":["**下載 SimpleITK套件**"]},{"cell_type":"code","metadata":{"id":"M0qDAfsfyR_a","colab_type":"code","outputId":"3e0ff5c1-920e-4dc5-d1be-ae4089bbeb4f","executionInfo":{"status":"ok","timestamp":1578582696640,"user_tz":-480,"elapsed":14004,"user":{"displayName":"林映辰林映辰","photoUrl":"","userId":"18165578179636605442"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["path=\"drive/My Drive/CT\"\n","!pip install SimpleITK"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting SimpleITK\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n","\u001b[K     |████████████████████████████████| 42.5MB 70kB/s \n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-1.2.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H-zSnM0rTSsF","colab_type":"text"},"source":["**設定3D vgg16**"]},{"cell_type":"code","metadata":{"id":"MsixZ0h6ybbi","colab_type":"code","outputId":"da8394e3-243b-47ad-8dc5-9f66e3d04074","executionInfo":{"status":"ok","timestamp":1578582698138,"user_tz":-480,"elapsed":5805,"user":{"displayName":"林映辰林映辰","photoUrl":"","userId":"18165578179636605442"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Activation, Dropout, Flatten,Dropout\n","from keras.layers import Conv3D\n","from keras.layers import MaxPooling3D\n","\n","input_shape = (128, 128, 64, 1)\n","\n","model = Sequential([\n","    Conv3D(64, (2, 2,2), input_shape=input_shape, padding='same',\n","           activation='relu'),\n","    Conv3D(64, (2, 2,2), activation='relu', padding='same'),\n","    MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2)),\n","    Conv3D(128, (2, 2,2), activation='relu', padding='same'),\n","    Conv3D(128, (2, 2,2), activation='relu', padding='same',),\n","    MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2)),\n","    Conv3D(256, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(256, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(256, (2, 2,2), activation='relu', padding='same',),\n","    MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2)),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2)),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    Conv3D(512, (2, 2,2), activation='relu', padding='same',),\n","    MaxPooling3D(pool_size=(2, 2,2), strides=(2, 2,2)),\n","    Flatten(),\n","    Dense(4096, activation='relu'),\n","    Dense(4096, activation='relu'),\n","    Dropout(0.25),\n","    Dense(4, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv3d_1 (Conv3D)            (None, 128, 128, 64, 64)  576       \n","_________________________________________________________________\n","conv3d_2 (Conv3D)            (None, 128, 128, 64, 64)  32832     \n","_________________________________________________________________\n","max_pooling3d_1 (MaxPooling3 (None, 64, 64, 32, 64)    0         \n","_________________________________________________________________\n","conv3d_3 (Conv3D)            (None, 64, 64, 32, 128)   65664     \n","_________________________________________________________________\n","conv3d_4 (Conv3D)            (None, 64, 64, 32, 128)   131200    \n","_________________________________________________________________\n","max_pooling3d_2 (MaxPooling3 (None, 32, 32, 16, 128)   0         \n","_________________________________________________________________\n","conv3d_5 (Conv3D)            (None, 32, 32, 16, 256)   262400    \n","_________________________________________________________________\n","conv3d_6 (Conv3D)            (None, 32, 32, 16, 256)   524544    \n","_________________________________________________________________\n","conv3d_7 (Conv3D)            (None, 32, 32, 16, 256)   524544    \n","_________________________________________________________________\n","max_pooling3d_3 (MaxPooling3 (None, 16, 16, 8, 256)    0         \n","_________________________________________________________________\n","conv3d_8 (Conv3D)            (None, 16, 16, 8, 512)    1049088   \n","_________________________________________________________________\n","conv3d_9 (Conv3D)            (None, 16, 16, 8, 512)    2097664   \n","_________________________________________________________________\n","conv3d_10 (Conv3D)           (None, 16, 16, 8, 512)    2097664   \n","_________________________________________________________________\n","max_pooling3d_4 (MaxPooling3 (None, 8, 8, 4, 512)      0         \n","_________________________________________________________________\n","conv3d_11 (Conv3D)           (None, 8, 8, 4, 512)      2097664   \n","_________________________________________________________________\n","conv3d_12 (Conv3D)           (None, 8, 8, 4, 512)      2097664   \n","_________________________________________________________________\n","conv3d_13 (Conv3D)           (None, 8, 8, 4, 512)      2097664   \n","_________________________________________________________________\n","max_pooling3d_5 (MaxPooling3 (None, 4, 4, 2, 512)      0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 16384)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              67112960  \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 4)                 16388     \n","=================================================================\n","Total params: 96,989,828\n","Trainable params: 96,989,828\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tLMVoJNSTWes","colab_type":"text"},"source":["**匯入資料**"]},{"cell_type":"code","metadata":{"id":"c6o5oKfmye26","colab_type":"code","outputId":"4e55e977-1733-471e-95ac-6a2dc7b65108","executionInfo":{"status":"ok","timestamp":1578582812689,"user_tz":-480,"elapsed":114545,"user":{"displayName":"林映辰林映辰","photoUrl":"","userId":"18165578179636605442"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import pandas as pd\n","import SimpleITK as sitk\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","#設定label\n","label_df=pd.read_csv(path+\"label.csv\")\n","labels=label_df['Grade']\n","\n","#onehot encoding \n","labels_onehot=np_utils.to_categorical(labels,4)\n","\n","# 宣告一個list存放mask\n","trainmasks_list=list()\n","\n","#讀進資料\n","for m in label_df['mask_name']:\n","  print(\"讀進:\",m)\n","  trainmask = sitk.ReadImage(path+\"/xVertSeg.v1/Data1/bone_masks/\"+str(m)+\".mhd\")\n","\n","  trainmasks=sitk.GetArrayFromImage(trainmask)\n","  trainmasks=trainmasks/trainmasks.max()\n","  print(trainmasks.min())\n","  print(\"trainmasks shape:\",trainmasks.shape)\n","  \n","  new_trainmasks=np.expand_dims(trainmasks,axis=3)\n","  print(\"expand trainmasks shape:\",new_trainmasks.shape)\n","\n","  trainmasks_list.append(new_trainmasks)\n","  bone_masks_data=np.array(trainmasks_list)\n","print(\"bone masks data shape:\",bone_masks_data.shape)\n","\n","#切割 raw data為訓練集和驗證集\n","x_train,x_test,y_train,y_test=train_test_split(bone_masks_data,labels_onehot,test_size=0.2,random_state=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["讀進: bone_mask_L1_1\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_2\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_3\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_4\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_5\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_6\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_7\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_8\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_9\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_10\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_11\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_12\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_13\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_14\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L1_15\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_1\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_2\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_3\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_4\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_5\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_6\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_7\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_8\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_9\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_10\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_11\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_12\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_13\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_14\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L2_15\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_1\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_2\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_3\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_4\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_5\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_6\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_7\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_8\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_9\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_10\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_11\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_12\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_13\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_14\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L3_15\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_1\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_2\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_3\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_4\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_5\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_6\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_7\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_8\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_9\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_10\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_11\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_12\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_13\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_14\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L4_15\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_1\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_2\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_3\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_4\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_5\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_6\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_7\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_8\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_9\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_10\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_11\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_12\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_13\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_14\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","讀進: bone_mask_L5_15\n","0.0\n","trainmasks shape: (128, 128, 64)\n","expand trainmasks shape: (128, 128, 64, 1)\n","bone masks data shape: (75, 128, 128, 64, 1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rryEhyfvTX8s","colab_type":"text"},"source":["**開始訓練**"]},{"cell_type":"code","metadata":{"id":"GUGTaAbLzOf7","colab_type":"code","outputId":"3a73d7c1-393e-4216-add0-05a353fc89e6","executionInfo":{"status":"ok","timestamp":1578583716760,"user_tz":-480,"elapsed":911082,"user":{"displayName":"林映辰林映辰","photoUrl":"","userId":"18165578179636605442"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import numpy as np\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","\n","#參數可自行調整\n","model.compile(optimizer = Adam(lr=1e-5), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=4,epochs=40)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 60 samples, validate on 15 samples\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","60/60 [==============================] - 37s 623ms/step - loss: 1.3851 - acc: 0.3500 - val_loss: 1.3821 - val_acc: 0.6667\n","Epoch 2/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.3771 - acc: 0.4667 - val_loss: 1.3596 - val_acc: 0.6000\n","Epoch 3/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.3170 - acc: 0.4833 - val_loss: 1.1849 - val_acc: 0.6000\n","Epoch 4/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.2486 - acc: 0.4500 - val_loss: 1.0956 - val_acc: 0.5333\n","Epoch 5/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1982 - acc: 0.3833 - val_loss: 1.1542 - val_acc: 0.2000\n","Epoch 6/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.1937 - acc: 0.4000 - val_loss: 1.1169 - val_acc: 0.3333\n","Epoch 7/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1811 - acc: 0.5167 - val_loss: 1.0786 - val_acc: 0.6000\n","Epoch 8/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1797 - acc: 0.4500 - val_loss: 1.0800 - val_acc: 0.6000\n","Epoch 9/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1784 - acc: 0.4833 - val_loss: 1.1175 - val_acc: 0.4667\n","Epoch 10/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1787 - acc: 0.5833 - val_loss: 1.0648 - val_acc: 0.6000\n","Epoch 11/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.1604 - acc: 0.5833 - val_loss: 1.0936 - val_acc: 0.5333\n","Epoch 12/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.1599 - acc: 0.5167 - val_loss: 1.0914 - val_acc: 0.5333\n","Epoch 13/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1615 - acc: 0.5333 - val_loss: 1.0464 - val_acc: 0.6000\n","Epoch 14/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1208 - acc: 0.6167 - val_loss: 1.0755 - val_acc: 0.4667\n","Epoch 15/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1308 - acc: 0.5833 - val_loss: 1.0794 - val_acc: 0.5333\n","Epoch 16/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.1143 - acc: 0.5833 - val_loss: 1.0630 - val_acc: 0.5333\n","Epoch 17/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.1084 - acc: 0.5833 - val_loss: 1.1211 - val_acc: 0.4667\n","Epoch 18/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.0920 - acc: 0.5833 - val_loss: 1.0916 - val_acc: 0.5333\n","Epoch 19/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.0644 - acc: 0.5667 - val_loss: 1.1108 - val_acc: 0.4000\n","Epoch 20/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.0651 - acc: 0.6000 - val_loss: 1.0743 - val_acc: 0.5333\n","Epoch 21/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.0428 - acc: 0.5500 - val_loss: 1.0463 - val_acc: 0.6000\n","Epoch 22/50\n","60/60 [==============================] - 18s 295ms/step - loss: 1.0751 - acc: 0.5667 - val_loss: 1.0556 - val_acc: 0.6000\n","Epoch 23/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.0448 - acc: 0.6000 - val_loss: 1.1242 - val_acc: 0.5333\n","Epoch 24/50\n","60/60 [==============================] - 18s 294ms/step - loss: 1.0381 - acc: 0.6333 - val_loss: 1.0473 - val_acc: 0.6000\n","Epoch 25/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9942 - acc: 0.6167 - val_loss: 1.1468 - val_acc: 0.4667\n","Epoch 26/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9864 - acc: 0.6167 - val_loss: 1.0608 - val_acc: 0.6000\n","Epoch 27/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9534 - acc: 0.6167 - val_loss: 1.1785 - val_acc: 0.4667\n","Epoch 28/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.9734 - acc: 0.5667 - val_loss: 1.1744 - val_acc: 0.5333\n","Epoch 29/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.9722 - acc: 0.6333 - val_loss: 1.1410 - val_acc: 0.6000\n","Epoch 30/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9211 - acc: 0.5833 - val_loss: 1.1568 - val_acc: 0.6000\n","Epoch 31/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.9232 - acc: 0.6500 - val_loss: 1.2128 - val_acc: 0.5333\n","Epoch 32/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9122 - acc: 0.5833 - val_loss: 1.2789 - val_acc: 0.5333\n","Epoch 33/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.8990 - acc: 0.6167 - val_loss: 1.0665 - val_acc: 0.6000\n","Epoch 34/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.9253 - acc: 0.6000 - val_loss: 1.5273 - val_acc: 0.4667\n","Epoch 35/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.8844 - acc: 0.6500 - val_loss: 1.1406 - val_acc: 0.6000\n","Epoch 36/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.8253 - acc: 0.6333 - val_loss: 1.1651 - val_acc: 0.6000\n","Epoch 37/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.8032 - acc: 0.6667 - val_loss: 1.1950 - val_acc: 0.6000\n","Epoch 38/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.8098 - acc: 0.6333 - val_loss: 1.3006 - val_acc: 0.6000\n","Epoch 39/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.7656 - acc: 0.6833 - val_loss: 1.4212 - val_acc: 0.6000\n","Epoch 40/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.7124 - acc: 0.7167 - val_loss: 1.2020 - val_acc: 0.6000\n","Epoch 41/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.6925 - acc: 0.7000 - val_loss: 1.7352 - val_acc: 0.4000\n","Epoch 42/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.6793 - acc: 0.6833 - val_loss: 1.3455 - val_acc: 0.6000\n","Epoch 43/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.6537 - acc: 0.7500 - val_loss: 1.4573 - val_acc: 0.6000\n","Epoch 44/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.5413 - acc: 0.7500 - val_loss: 1.4855 - val_acc: 0.6000\n","Epoch 45/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.5768 - acc: 0.7333 - val_loss: 1.9898 - val_acc: 0.3333\n","Epoch 46/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.5198 - acc: 0.8000 - val_loss: 1.7150 - val_acc: 0.4667\n","Epoch 47/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.7098 - acc: 0.7167 - val_loss: 1.3683 - val_acc: 0.6000\n","Epoch 48/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.4616 - acc: 0.8333 - val_loss: 1.7653 - val_acc: 0.3333\n","Epoch 49/50\n","60/60 [==============================] - 18s 294ms/step - loss: 0.4957 - acc: 0.8000 - val_loss: 1.6556 - val_acc: 0.6000\n","Epoch 50/50\n","60/60 [==============================] - 18s 295ms/step - loss: 0.4141 - acc: 0.8667 - val_loss: 2.0101 - val_acc: 0.4000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f98cd606ba8>"]},"metadata":{"tags":[]},"execution_count":5}]}]}